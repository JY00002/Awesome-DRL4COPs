<!-- 
   ================================
   README for "Awesome-DRL4COPs: Deep Reinforcement Learning for Combinatorial Optimization Problems"
   ================================
-->

<h1 align="center">
  üöÅ Awesome-DRL4COPs: Deep Reinforcement Learning for Combinatorial Optimization Problems üöÄ
</h1>

<p align="center">
  <!-- 1) Awesome Badge -->
  <a href="https://awesome.re" target="_blank">
    <img src="https://awesome.re/badge.svg" alt="Awesome Badge"/>
  </a>
  
  <!-- 2) Maintain Status Badge -->
  <img src="https://img.shields.io/badge/Maintain-Active-8A2BE2?style=flat-square&logo=github&logoColor=white" alt="Maintain Badge"/>

  <!-- 3) PR's Welcome Badge -->
  <a href="http://makeapullrequest.com" target="_blank">
    <img src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat" alt="PR's Welcome"/>
  </a>

  <!-- 4) Visitor Badge: replace 'YourGitHubName' with your GitHub username or org name -->
  <a href="[https://github.com/JY00002/Awesome-DRL4COPs](https://github.com/JY00002/Awesome-DRL4COPs)" target="_blank">
    <img src="https://visitor-badge.laobi.icu/badge?page_id=YourGitHubName.Awesome-DRL4COPs&left_color=%239146DE&right_color=%23E6C82D" alt="Visitor Badge"/>
  </a>
</p>

<p align="center">
  <strong>Where Deep Reinforcement Learning for Combinatorial Optimization Problems!</strong>
</p>

<hr/>

<!-- About Section -->
# üè°About
This repository accompanies the work:  
**Deep reinforcement learning for combinatorial optimization problems: a comprehensive literature review** 

This is an active repository, you can watch for the latest advances.  
If you find it useful, please star ‚≠ê this repo and [cite](#citation) the paper.

---

## üî• News
- **[2025-07-23]** üéâ Our paper *"Deep reinforcement learning for combinatorial optimization problems: a comprehensive literature review"* has been **submited to  _Artificial Intelligence Review_**.

> If you have any questions or suggestions, please feel free to open an [issue](https://github.com/JY00002/Awesome-DRL4COPs/issues) or contact us via [email](shengyunwei@nudt.edu.cn).

---

## Introduction
This repository accompanies our work on **"Deep reinforcement learning for combinatorial optimization problems: a comprehensive literature review"**.  
Here, we primarily store various **tables** referenced in the survey/overview paper. These tables focus on:

- Summarization of typical **VRP, JSP, and FSP**  
- **COPs benchmark datasets** and SOTA results

> **Note**: The goal is to provide a structured, easy-to-navigate resource for researchers interested in the intersection of DRL and COPs.

---

## Shop Scheduling Problem and Links

| ID | Paper Title | Problem | Year | Code |
|:---:|------------|:-------:|:----:|:------|
| 1 | Learning to Dispatch for Job Shop Scheduling via Deep Reinforcement Learning | CJSP | 2020 | [üíª](https://github.com/zcajiayin/L2D) |
| 2 | Matrix Encoding Networks for Neural Combinatorial Optimization | FFSP/TSP | 2021 | [üíª](https://github.com/yd-kwon/MatNet) |
| 3 | Explainable reinforcement learning in production control of job shop manufacturing system | MJSP | 2022 | [üíª](https://github.com/AndreasKuhnle/SimRLFab) |
| 4 | A multi-action deep reinforcement learning framework for flexible Job-shop scheduling problem | FJSP | 2022 | [üíª](https://github.com/pengguo318/FJSPDRL) |
| 5 | Multi-objective reinforcement learning framework for dynamic flexible job shop scheduling problem with uncertain events | MDFJSP | 2022 | [üíª](https://codeocean.com/capsule/6421616/tree/v1) |
| 6 | Solving job scheduling problems in a resource preemption environment with multi-agent reinforcement learning | FFSP | 2022 | [üíª](https://github.com/MISTCARRYYOU/MASA-QMIX) |
| 7 | Solving job shop scheduling problems via deep reinforcement learning | CJSP | 2023 | [üíª](https://doi.org/10.24433/CO.4361242.v1) |
| 8 | A spatial pyramid pooling-based deep reinforcement learning model for dynamic job-shop scheduling problem | DJSP | 2023 | [üíª](https://github.com/sx1616039/DJSP) |
| 9 | Job Shop Scheduling via Deep Reinforcement Learning: A Sequence to Sequence Approach | CJSP | 2023 | [üíª](https://github.com/dawoz/JSP-DeepRL-Seq2Seq) |
| 10 | A deep multi-agent reinforcement learning approach to solve dynamic job shop scheduling problem | DJSP | 2023 | [üíª](https://github.com/RK0731/Deep-MARL-for-Dynamic-JSP) |
| 11 | Flexible Job-Shop Scheduling via Graph Neural Network and Deep Reinforcement Learning | FJSP | 2023 | [üíª](https://github.com/songwenas12/fjsp-drl) |
| 12 | Graph-based Reinforcement Learning for Flexible Job Shop Scheduling with Transportation Constraints | FJSP | 2023 | [üíª](https://github.com/msh0576/FJSPT-Scheduler) |
| 13 | A deep reinforcement learning model for dynamic job-shop scheduling problem with uncertain processing time | DJSP | 2024 | [üíª](https://github.com/sx1616039/DRL4DJSP) |
| 14 | An efficient and adaptive design of reinforcement learning environment to solve job shop scheduling problem with soft actor-critic algorithm | CJSP | 2024 | [üíª](https://github.com/JonaSi754/JSP-RL-Environment) |
| 15 | Introducing PetriRL: An innovative framework for JSSP resolution integrating Petri nets and event-based reinforcement learning | CJSP | 2024 | [üíª](https://github.com/Sofiene-Uni/Intralogistics) |
| 16 | An actor-critic algorithm with policy gradients to solve the job shop scheduling problem using deep double recurrent agents | CJSP | 2024 | [üíª](https://github.com/GiorgioGrani/JSSP_actor-critic_Agasucci_Monaci_Grani) |
| 17 | Deep Reinforcement Learning Guided Improvement Heuristic for Job Shop Scheduling | CJSP | 2024 | [üíª](https://github.com/zcaicaros/L2S) |
| 18 | Learning to Solve Job Shop Scheduling under Uncertainty | CJSP | 2024 | [üíª](https://github.com/jolibrain/wheatley) |
| 19 | Residual Scheduling: A New Reinforcement Learning Approach to Solving Job Shop Scheduling Problem | FJSP | 2024 | [üíª](https://github.com/Raydiation/ResidualScheduling_IEEE_access) |
| 20 | Design and calibration of a DRL algorithm for solving the job shop scheduling problem under unexpected job arrivals | MDJSP | 2024 | [üíª](https://github.com/Nour0602/DRL_ADD_JSSP) |
| 21 | Graph reinforcement learning for flexible job shop scheduling under industrial demand response: A production and energy nexus perspective | MFJSP | 2024 | [üíª](https://github.com/ruizhangjie/FJS-IDR) |
| 22 | Fast Pareto set approximation for multi-objective flexible job shop scheduling via parallel preference-conditioned graph reinforcement learning | MFJSP | 2024 | [üíª](https://github.com/Chupeng24/PGRL) |
| 23 | Large-Scale Dynamic Scheduling for Flexible Job-Shop With Random Arrivals of New Jobs by Hierarchical Reinforcement Learning | DFJSP | 2024 | [üíª](https://github.com/ruizhangjie/FJS-IDR) |
| 24 | End-to-end Multi-Target Flexible Job Shop Scheduling with Deep Reinforcement Learning | MFJSP | 2024 | [üíª](https://github.com/RKWin93/E2E-MAPPO-for-MT-FJSP) |
| 25 | Flexible Job Shop Scheduling via Dual Attention Network-Based Reinforcement Learning | FJSP | 2024 | [üíª](https://github.com/wrqccc/FJSP-DRL) |
| 26 | A discrete event simulator to implement deep reinforcement learning for the dynamic flexible job shop scheduling problem | DFJSP | 2024 | [üíª](http://doi.org/10.13140/RG.2.2.21002.64966) |
| 27 | Study on the application of single-agent and multi-agent reinforcement learning to dynamic scheduling in manufacturing environments with growing complexity: Case study on the synthesis of an industrial IoT Test Bed | DFJSP | 2024 | [üíª](https://zenodo.org/record/10212298) |
| 28 | Flow-Shop Scheduling Problem With Batch Processing Machines via Deep Reinforcement Learning for Industrial Internet of Things | CFSP | 2024 | [üíª](https://github.com/ZihuiLuo/FSSP-BPM/tree/master) |
| 29 | A recurrent reinforcement learning strategy for optimal scheduling of partially observable job-shop and flow-shop batch chemical plants under uncertainty | MDFSP | 2024 | [üíª](https://git.uwaterloo.ca/ricardez_group/luis-ricardez-sandoval-drqn) |
| 30 | Robust-stable scheduling in dynamic flow shops based on deep reinforcement learning | MDFSP | 2024 | [üíª](https://doi.org/10.17605/OSF.IO/SXM3Q) |
| 31 | Diverse policy generation for the flexible job-shop scheduling problem via deep reinforcement learning with a novel graph representation | FJSP | 2025 | [üíª](https://github.com/Echever/RL-for-FJSSP) |
| 32 | A modified multi-agent proximal policy optimization algorithm for multi-objective dynamic partial-re-entrant hybrid flow shop scheduling problem | MDFFSP | 2025 | [üíª](https://github.com/GarveyPython/MDPR-HFSP) |
| 33 | Dynamic scheduling for multi-objective flexible job shop via deep reinforcement learning | MDFJSP | 2025 | [üíª](https://github.com/cslxju/DMOFJSSP_DRL) |

## Routing Problems and Links

| ID | Paper Title | Problem | Year | Code |
|:---:|------------|:-------:|:----:|:------|
| 1 | Attention, Learn to Solve Routing Problems | TSP, CVRP, SDVRP, OP, PCTSP, SPCTSP | 2019 | [üíª](https://github.com/wouterkool/attention-learn-to-route) |
| 2 | A Learning-Based Iterative Method for Solving Vehicle Routing Problems | CVRP | 2020 | [üíª](https://github.com/rlopt/l2i) |
| 3 | POMO: Policy Optimization with Multiple Optima for Reinforcement Learning | TSP, CVRP, KP | 2020 | [üíª](https://github.com/yd-kwon/POMO) |
| 4 | Learning to Iteratively Solve Routing Problems with Dual-Aspect Collaborative Transformer | TSP, CVRP | 2021 | [üíª](https://github.com/yining043/VRP-DACT) |
| 5 | Multi-Decoder Attention Model with Embedding Glimpse for Solving Vehicle Routing Problems | TSP, CVRP, SDVRP, OP, PCTSP, SPCTS | 2021 | [üíª](https://github.com/liangxinedu/MDAM) |
| 6 | Generalize a Small Pre-trained Model to Arbitrarily Large TSP Instances | TSP | 2021 | [üíª](https://github.com/Spider-scnu/TSP) |
| 7 | Dynamic Graph Combinatorial Optimization with Multi-Attention Deep Reinforcement Learning | DTSP, DVRP | 2022 | [üíª](https://github.com/udeshmg/GTA-RL) |
| 8 | Sym-NCO: Leveraging Symmetricity for Neural Combinatorial Optimization | TSP, CVRP, PCTSP, OP | 2022 | [üíª](https://github.com/alstn12088/Sym-NCO) |
| 9 | Learning Improvement Heuristics for Solving Routing Problems | TSP, CVRP | 2022 | [üíª](https://github.com/WXY1427/Learn-Improvement-Heuristics-for-Routing) |
| 10 | Solve routing problems with a residual edge-graph attention neural network | TSP, CVRP | 2022 | [üíª](https://github.com/Lei-Kun/DRL-and-graph-neural-network-for-routing-problems) |
| 11 | Meta-Learning-Based Deep Reinforcement Learning for Multiobjective Optimization Problems | MTSP, MVRPTW | 2023 | [üíª](https://github.com/zhangzizhen/ML-DAM) |
| 12 | Neural Improvement Heuristics for Graph Combinatorial Optimization Problems | TSP, PRP, GPP | 2023 | [üíª](https://github.com/TheLeprechaun25/neural-improvement-heuristics) |
| 13 | H-TSP: Hierarchically Solving the Large-Scale Traveling Salesman Problem | TSP | 2023 | [üíª](https://github.com/Learning4Optimization-HUST/H-TSP) |
| 14 | Pointerformer: Deep Reinforced Multi-Pointer Transformer for the Traveling Salesman Problem | TSP | 2023 | [üíª](https://github.com/Pointerformer/Pointerformer) |
| 15 | Cross-Problem Learning for Solving Vehicle Routing Problems | TSP, OP, PCTSP, CVRP | 2024 | [üíª](https://github.com/Zhuoyi-Lin/Cross_problem_learning) |
| 16 | Deep Reinforcement Learning for Solving Vehicle Routing Problems With Backhauls | VRPB | 2024 | [üíª](https://github.com/wangconghui0/VRPB) |
| 17 | GLOP: Learning Global Partition and Local Construction for Solving Large-Scale Routing Problems in Real-Time | TSP, ATSP, CVRP, PCTSP | 2024 | [üíª](https://github.com/henry-yeh/GLOP) |
| 18 | Learning Feature Embedding Refiner for Solving Vehicle Routing Problems | TSP, CVRP | 2024 | [üíª](https://github.com/Demon0312/Feature-Embedding-Refiner) |
| 19 | Multi-Type Attention for Solving Multi-Depot Vehicle Routing Problems | MDVRP, MDOVRP | 2024 | [üíª](https://github.com/Good9T/MD_MTA) |
| 20 | MVMoE: Multi-Task Vehicle Routing Solver with Mixture-of-Experts | CVRP, OVRP, VRPB, VRPL, VRPTW, OVRPTW (16 types) | 2024 | [üíª](https://github.com/RoyalSkye/Routing-MVMoE) |
| 21 | Reinforcement Learning for Solving Stochastic Vehicle Routing Problem with Time Windows | VRPTW | 2024 | [üíª](https://github.com/Zangir/SVRP) |
| 22 | RouteFinder: Towards Foundation Models for Vehicle Routing Problems | CVRP, OVRP, VRPB, VRPL, VRPTW, OVRPTW, OVRPB, OVRPL, VRPBL, VRPBTW, VRPLTW | 2024 | [üíª](https://github.com/ai4co/routefinder) |
| 23 | Token-based deep reinforcement learning for Heterogeneous VRP with Service Time Constraints | HVRP | 2024 | [üíª](https://github.com/Vision-Intelligence-and-Robots-Group/ToDRL) |
| 24 | Multi-Task Learning for Routing Problem with Cross-Problem Zero-Shot Generalization | CVRP, VRPTW, OVRP, VRPB, VRPL, VRPBL, VRPBTW, OVRPL, OVRPLTW, OVRPBTW | 2024 | [üíª](https://github.com/FeiLiu36/MTNCO) |
| 25 | A comparison of reinforcement learning policies for dynamic vehicle routing problems with stochastic customer requests | DVRP | 2025 | [üíª](https://github.com/frakkerman/dynamic_vrp_rl) |
| 26 | Attention-Enhanced Deep Reinforcement Learning for Electric Vehicle Routing Optimization | E-VRP | 2025 | [üíª](https://github.com/forward-no/AEDRL) |
